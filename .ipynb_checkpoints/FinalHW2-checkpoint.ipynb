{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Aditya Bhatt\n",
    "\n",
    "Student Netid: apb462\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include aspects of the Data Science Workflow that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place your answer here!\n",
    "I would take in the all the data and:\n",
    "1. I would define the goal properly, and find out what can be predicted and estimated. Th goal would be to make Target the go-to market for Pregnant Woman even after birth.\n",
    "2. Perform data exploration with all the retrived data, after data cleaning.\n",
    "3. I would visualize the data and check if there are any anomalies in the data.\n",
    "4. I would find out how the data was sampled, which data is relevant, by finding the covariance between data when it comes to pregnant mothers. All pregnant mothers' data would be taken and relationships with other data would be found, convariance with types of products bought by them and the products themeselves, etc.\n",
    "5. I would also check if there are privacy issues, if some data seems to be more delicate than other types of data.\n",
    "6. I would check the data set for common patterns, I would perform data mining and finding association rules using an Apriori analysis to check if Pregnant Women data has patterns with any other type of data out there.\n",
    "7. I would then build the model, and make it compatible with the data, so that it can fit the data. To validate the model, I would cross check it with the found association rules and see what matches and what doesn't match. \n",
    "8. I will find out what we leaned from here and how it can be improved apon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Exploring data in the command line\n",
    "For this part we will be using the data file located in `\"data/advertising_events.csv\"`. This file consists of records that pertain to some online advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int` (continuous), `int` (continuous), `string`, and `int` (category) respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`.\n",
    "\n",
    "[Hints: You can experiment with whatever you want in the notebook and then delete things to construct your answer later.  Recall that once you enter the \"!\" then filename completion should work.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records (lines) are in this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10341\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!wc -l < advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many unique users are in this file? (hint: consider the 'cut' command and use pipe operator '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!cut -d',' -f1 advertising_events.csv | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Rank all domains by the number of visits they received in descending order. (hint: consider the 'cut', 'uniq' and 'sort' commands and the pipe operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3114 google.com\n",
      "   2092 facebook.com\n",
      "   1036 youtube.com\n",
      "   1034 yahoo.com\n",
      "   1022 baidu.com\n",
      "    513 wikipedia.org\n",
      "    511 amazon.com\n",
      "    382 qq.com\n",
      "    321 twitter.com\n",
      "    316 taobao.com\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!cut -f3 -d, advertising_events.csv | sort | uniq -c | sort -nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. List all records for the user with user id 37. (hint: this can be done using 'grep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,648061658,google.com,0\n",
      "37,642479972,google.com,2\n",
      "37,644493341,facebook.com,2\n",
      "37,654941318,facebook.com,1\n",
      "37,649979874,baidu.com,1\n",
      "37,653061949,yahoo.com,1\n",
      "37,655020469,google.com,3\n",
      "37,640878012,amazon.com,0\n",
      "37,659864136,youtube.com,1\n",
      "37,640361378,yahoo.com,1\n",
      "37,653862134,facebook.com,0\n",
      "37,648828970,youtube.com,0\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!awk -F, '$1 == 37' advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any others you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data set `\"datasets/ads_dataset.tsv\"` into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your code here\n",
    "data = pd.read_csv(\"ads_dataset.tsv\",sep='\\t')\n",
    "ads = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` [(manual page)](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     number_nan  number_distinct        mean          max  \\\n",
      "buy_freq                52257.0             10.0    1.240653     15.00000   \n",
      "buy_interval                0.0            295.0    0.210008    174.62500   \n",
      "expected_time_buy           0.0            348.0   -0.198040     84.28571   \n",
      "expected_time_visit         0.0          15135.0  -10.210786     91.40192   \n",
      "isbuyer                     0.0              2.0    0.042632      1.00000   \n",
      "last_buy                    0.0            189.0   64.729335    188.00000   \n",
      "last_visit                  0.0            189.0   64.729335    188.00000   \n",
      "multiple_buy                0.0              2.0    0.006357      1.00000   \n",
      "multiple_visit              0.0              2.0    0.277444      1.00000   \n",
      "num_checkins                0.0           4628.0  720.657592  37091.00000   \n",
      "sv_interval                 0.0           5886.0    5.825610    184.91670   \n",
      "uniq_urls                   0.0            207.0   86.569343    206.00000   \n",
      "visit_freq                  0.0             64.0    1.852777     84.00000   \n",
      "y_buy                       0.0              2.0    0.004635      1.00000   \n",
      "\n",
      "                          min          std    25%    50%         75%  \n",
      "buy_freq               1.0000     0.782228    1.0    1.0    1.000000  \n",
      "buy_interval           0.0000     3.922016    0.0    0.0    0.000000  \n",
      "expected_time_buy   -181.9238     4.997792    0.0    0.0    0.000000  \n",
      "expected_time_visit -187.6156    31.879722    0.0    0.0    0.000000  \n",
      "isbuyer                0.0000     0.202027    0.0    0.0    0.000000  \n",
      "last_buy               0.0000    53.476658   18.0   51.0  105.000000  \n",
      "last_visit             0.0000    53.476658   18.0   51.0  105.000000  \n",
      "multiple_buy           0.0000     0.079479    0.0    0.0    0.000000  \n",
      "multiple_visit         0.0000     0.447742    0.0    0.0    1.000000  \n",
      "num_checkins           1.0000  1275.727306  127.0  319.0  802.000000  \n",
      "sv_interval            0.0000    17.595442    0.0    0.0    0.104167  \n",
      "uniq_urls             -1.0000    61.969765   30.0   75.0  155.000000  \n",
      "visit_freq             0.0000     2.921820    1.0    1.0    2.000000  \n",
      "y_buy                  0.0000     0.067924    0.0    0.0    0.000000  \n"
     ]
    }
   ],
   "source": [
    "def getDfSummary(input_data):\n",
    "    # Place your code here\n",
    "    #dict1 = input_data['isbuyer'].value_counts(dropna=False)\n",
    "   #print(dict1)\n",
    "    #numberNanIsBuyer = input_data['isbuyer'].value_counts(dropna=False)\n",
    "    #if float('nan') in numberNanIsBuyer:\n",
    "    #    numberNanIsBuyer = numberNanIsBuyer[float('nan')]\n",
    "    #else:\n",
    "    #    numberNanIsBuyer = 0\n",
    "    #numDistinctisBuyer = len(input_data['isbuyer'].value_counts(dropna=True))\n",
    "    #print(numberNanIsBuyer)\n",
    "    #print(numDistinctisBuyer)\n",
    "    #print(\"-----\")\n",
    "    #numberNanbuy_freq = input_data['buy_freq'].value_counts(dropna=False)\n",
    "    #if float('nan') in numberNanbuy_freq:\n",
    "    #    numberNanbuy_freq = numberNanbuy_freq[float('nan')]\n",
    "    #else:\n",
    "    #    numberNanbuy_freq = 0\n",
    "    #print(input_data['buy_freq'].value_counts(dropna=False))\n",
    "    #numDistinctbuy_freq = len(input_data['buy_freq'].value_counts(dropna=True))\n",
    "    #print(numberNanbuy_freq)\n",
    "    #print(numDistinctbuy_freq)\n",
    "    #print(\"-----\")\n",
    "    numberNan = {} #initializing variables for loop at comes after. this willbe used to create the new data frame \n",
    "    numberDistinct = {}\n",
    "    mean = {}\n",
    "    maxi = {}\n",
    "    mini = {}\n",
    "    std = {}\n",
    "    per25 = {}\n",
    "    per50 = {}\n",
    "    per75 = {}#below loop will loop across all variables in old data frame and calculate and store the new featues in above variables\n",
    "    for column in input_data:\n",
    "        numberNantemp = input_data[column].value_counts(dropna=False)\n",
    "        if float('nan') in numberNantemp:\n",
    "            numberNan[column] = numberNantemp[float('nan')] #getting relevenat data, need to check for NaNs first\n",
    "        else:\n",
    "            numberNan[column] = 0\n",
    "        numberDistinct[column] = len(input_data[column].value_counts(dropna=True)) #counting the number of distinct columns in value counts\n",
    "        #also making sure that dropna=True this ensures that NaNs are ignored\n",
    "        mean[column] = input_data[column].describe()['mean']\n",
    "        maxi[column] = input_data[column].describe()['max']#getting relevant data here \n",
    "        mini[column] = input_data[column].describe()['min']\n",
    "        std[column] = input_data[column].describe()['std']\n",
    "        per25[column] = input_data[column].describe()['25%']\n",
    "        per50[column] = input_data[column].describe()['50%']\n",
    "        per75[column] = input_data[column].describe()['75%']\n",
    "    \n",
    "    d = {}#this is the data to be created which will go into the data frame\n",
    "    for column in mean:\n",
    "        d[column] = numberNan[column],numberDistinct[column],mean[column],maxi[column],mini[column],std[column],per25[column],per50[column],per75[column]\n",
    "    #print(d)\n",
    "    output_data = pd.DataFrame(d)\n",
    "    output_data = output_data.T #transposing data frame to match question requirements\n",
    "    output_data.columns = ['number_nan','number_distinct','mean','max','min','std','25%','50%','75%']  #renaming columns for clarity\n",
    "    print(output_data)\n",
    "    #print(per50)\n",
    "    return output_data\n",
    "dct = getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `%timeit getDfSummary(ads)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     number_nan  number_distinct        mean          max  \\\n",
      "buy_freq                52257.0             10.0    1.240653     15.00000   \n",
      "buy_interval                0.0            295.0    0.210008    174.62500   \n",
      "expected_time_buy           0.0            348.0   -0.198040     84.28571   \n",
      "expected_time_visit         0.0          15135.0  -10.210786     91.40192   \n",
      "isbuyer                     0.0              2.0    0.042632      1.00000   \n",
      "last_buy                    0.0            189.0   64.729335    188.00000   \n",
      "last_visit                  0.0            189.0   64.729335    188.00000   \n",
      "multiple_buy                0.0              2.0    0.006357      1.00000   \n",
      "multiple_visit              0.0              2.0    0.277444      1.00000   \n",
      "num_checkins                0.0           4628.0  720.657592  37091.00000   \n",
      "sv_interval                 0.0           5886.0    5.825610    184.91670   \n",
      "uniq_urls                   0.0            207.0   86.569343    206.00000   \n",
      "visit_freq                  0.0             64.0    1.852777     84.00000   \n",
      "y_buy                       0.0              2.0    0.004635      1.00000   \n",
      "\n",
      "                          min          std    25%    50%         75%  \n",
      "buy_freq               1.0000     0.782228    1.0    1.0    1.000000  \n",
      "buy_interval           0.0000     3.922016    0.0    0.0    0.000000  \n",
      "expected_time_buy   -181.9238     4.997792    0.0    0.0    0.000000  \n",
      "expected_time_visit -187.6156    31.879722    0.0    0.0    0.000000  \n",
      "isbuyer                0.0000     0.202027    0.0    0.0    0.000000  \n",
      "last_buy               0.0000    53.476658   18.0   51.0  105.000000  \n",
      "last_visit             0.0000    53.476658   18.0   51.0  105.000000  \n",
      "multiple_buy           0.0000     0.079479    0.0    0.0    0.000000  \n",
      "multiple_visit         0.0000     0.447742    0.0    0.0    1.000000  \n",
      "num_checkins           1.0000  1275.727306  127.0  319.0  802.000000  \n",
      "sv_interval            0.0000    17.595442    0.0    0.0    0.104167  \n",
      "uniq_urls             -1.0000    61.969765   30.0   75.0  155.000000  \n",
      "visit_freq             0.0000     2.921820    1.0    1.0    2.000000  \n",
      "y_buy                  0.0000     0.067924    0.0    0.0    0.000000  \n",
      "0.3728945212060353\n",
      "0:00:00.375499\n",
      "it takes 0.3728945212060353 seconds for the function to work on the ads data frame\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "from timeit import default_timer as timerCount\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "begin = timerCount()#check starting timer\n",
    "start=datetime.now()\n",
    "dct = getDfSummary(ads)\n",
    "end = timerCount()\n",
    "elapsedTime = end-begin #get elapsed time here\n",
    "elapsedTime2 = datetime.now()-start\n",
    "print(elapsedTime)\n",
    "print(elapsedTime2)\n",
    "print(\"it takes {} seconds for the function to work on the ads data frame\".format(elapsedTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy_freq               52257.0\n",
      "buy_interval               0.0\n",
      "expected_time_buy          0.0\n",
      "expected_time_visit        0.0\n",
      "isbuyer                    0.0\n",
      "last_buy                   0.0\n",
      "last_visit                 0.0\n",
      "multiple_buy               0.0\n",
      "multiple_visit             0.0\n",
      "num_checkins               0.0\n",
      "sv_interval                0.0\n",
      "uniq_urls                  0.0\n",
      "visit_freq                 0.0\n",
      "y_buy                      0.0\n",
      "Name: number_nan, dtype: float64\n",
      "Fields that contains NaN values are:\n",
      "buy_freq\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "print(dct['number_nan']) \n",
    "print(\"Fields that contains NaN values are:\") #arr to store column names to print later\n",
    "arr = [\"buy_freq\",\"buy_interval\",\"expected_time_buy\",\"expected_time_visit\",\"isbuyer\",\"last_buy\",\"last_visit\",\"multiple_buy\",\"multiple_visit\",\"num_checkins\",\"sv_interval\",\"uniq_urls\",\"visit_freq\",\"y_buy\"]\n",
    "for i in range(14):\n",
    "    #print(row)\n",
    "    if int(dct.iloc[i]['number_nan']) > 0: \n",
    "        print(arr[i]) #simple check for NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? What would be an appropriate method for filling in missing values?\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     number_nan  number_distinct        mean          max  \\\n",
      "buy_freq                52257.0              0.0         NaN          NaN   \n",
      "buy_interval                0.0              1.0    0.000000      0.00000   \n",
      "expected_time_buy           0.0              1.0    0.000000      0.00000   \n",
      "expected_time_visit         0.0          13351.0   -9.669298     91.40192   \n",
      "isbuyer                     0.0              1.0    0.000000      0.00000   \n",
      "last_buy                    0.0            189.0   65.741317    188.00000   \n",
      "last_visit                  0.0            189.0   65.741317    188.00000   \n",
      "multiple_buy                0.0              1.0    0.000000      0.00000   \n",
      "multiple_visit              0.0              2.0    0.255602      1.00000   \n",
      "num_checkins                0.0           4570.0  721.848518  37091.00000   \n",
      "sv_interval                 0.0           5112.0    5.686388    184.91670   \n",
      "uniq_urls                   0.0            207.0   86.656180    206.00000   \n",
      "visit_freq                  0.0             48.0    1.651549     84.00000   \n",
      "y_buy                       0.0              2.0    0.003024      1.00000   \n",
      "\n",
      "                          min          std    25%    50%         75%  \n",
      "buy_freq                  NaN          NaN    NaN    NaN         NaN  \n",
      "buy_interval           0.0000     0.000000    0.0    0.0    0.000000  \n",
      "expected_time_buy      0.0000     0.000000    0.0    0.0    0.000000  \n",
      "expected_time_visit -187.6156    31.239030    0.0    0.0    0.000000  \n",
      "isbuyer                0.0000     0.000000    0.0    0.0    0.000000  \n",
      "last_buy               0.0000    53.484622   19.0   52.0  106.000000  \n",
      "last_visit             0.0000    53.484622   19.0   52.0  106.000000  \n",
      "multiple_buy           0.0000     0.000000    0.0    0.0    0.000000  \n",
      "multiple_visit         0.0000     0.436203    0.0    0.0    1.000000  \n",
      "num_checkins           1.0000  1284.504018  126.0  318.0  803.000000  \n",
      "sv_interval            0.0000    17.623555    0.0    0.0    0.041667  \n",
      "uniq_urls             -1.0000    61.996711   30.0   75.0  155.000000  \n",
      "visit_freq             1.0000     2.147955    1.0    1.0    2.000000  \n",
      "y_buy                  0.0000     0.054904    0.0    0.0    0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Place your code and response here\n",
    "#print(ads['buy_freq'])\n",
    "dctBuyFreq = getDfSummary(ads[ads['buy_freq'].isnull()]) #this only keeps rows with NaNs in the data frame.\n",
    "#Answers:-\n",
    "#yes some features change a lot, buy_interval, expected_time_buy, isbuyer are drastically different, so it does not look at the data is missing at random. isBuyer seems to correlate almost perfectly\n",
    "#the fields mentioned above seem to correlate quite perfectly with the missing data field buy_freq. Method for filling in missing values could be by using regression of the values which have non-missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Which variables are binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields that contains binary values are:\n",
      "isbuyer\n",
      "multiple_buy\n",
      "multiple_visit\n",
      "y_buy\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "#binary variables are isBuyer, multiple_buy, multiple_visit, y_buy\n",
    "print(\"Fields that contains binary values are:\")\n",
    "arr = [\"buy_freq\",\"buy_interval\",\"expected_time_buy\",\"expected_time_visit\",\"isbuyer\",\"last_buy\",\"last_visit\",\"multiple_buy\",\"multiple_visit\",\"num_checkins\",\"sv_interval\",\"uniq_urls\",\"visit_freq\",\"y_buy\"]\n",
    "for i in range(14):\n",
    "    #print(row) #similar technique to previous question\n",
    "    if int(dct.iloc[i]['number_distinct']) == 2:\n",
    "        print(arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
